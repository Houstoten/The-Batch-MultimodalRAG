from langchain.retrievers.contextual_compression import ContextualCompressionRetriever
from langchain_cohere import CohereRerank
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
# from langchain.chains import RetrievalQA
from langchain_core.output_parsers import JsonOutputParser

from pydantic import BaseModel, Field

rag_prompt = """You are an advanced retrieval and generation assistant, trained to provide **detailed, accurate, and contextually relevant answers**. Leverage the provided **context**, user inputs, and embedded memory to construct logically sound and comprehensive responses.

### Task:
1. **Understand the Query**: Analyze user inputs to discern intent and determine the best retrieval and synthesis strategy.
2. **Employ Chain of Thought (CoT)**: Break down reasoning step by step to ensure depth, accuracy, and coherence in the response.
3. **Leverage Context**: Integrate contextual information with retrieved knowledge to ensure the answer aligns with the user's requirements.
4. **Generate Outputs Dynamically**: Tailor the response to the input format (text, image description, or both).

### Input Schema:
- **Context**: {context}
- **Text Input**: {text_input} (optional)
- **Image Description**: {image_description} (optional)

### Instructions by Scenario:
1. **Only Text Provided**:
   - Focus exclusively on the text input.
   - Extract key details from the context to complement the analysis.
2. **Only Image Description Provided**:
   - Analyze the described image thoroughly.
   - Use the context to enhance the interpretation of the visual elements.
3. **Both Text and Image Description Provided**:
   - Synthesize information from both inputs for a cohesive and nuanced response.

### Chain of Thought (CoT) Reasoning:
- **Step 1**: Analyze all inputs to determine the userâ€™s intent.
- **Step 2**: Identify the required knowledge domains and retrieve relevant information.
- **Step 3**: Verify the sufficiency of retrieved information against the context and inputs.
- **Step 4**: Formulate a detailed, coherent, and accurate response.

### Final Response:
- Structure: Ensure the output is clear, precise, and aligned with user intent.
- Depth: Provide additional insights or actionable recommendations where appropriate.
- Clarity: Avoid unnecessary jargon while maintaining technical accuracy.

---

### Example Queries for Different Scenarios

#### **Scenario 1: User Inputs Only Text**
**Context**: Recent advancements in quantum computing.
**Text Input**: "Explain the impact of qubits on computational speed."
**Response**: (Use CoT reasoning to address the question in depth, referencing the context on quantum computing.)

#### **Scenario 2: User Inputs Only Image Description**
**Context**: Environmental conservation initiatives.
**Image Description**: "A detailed image of a river surrounded by deforested land."
**Response**: (Analyze the environmental implications using the context and interpret the visual information.)

#### **Scenario 3: User Inputs Both Text and Image Description**
**Context**: Climate change and renewable energy.
**Text Input**: "What are the benefits of solar panels in urban areas?"
**Image Description**: "An image of a rooftop covered with solar panels."
**Response**: (Synthesize both inputs to create a comprehensive answer about urban solar panel benefits.)

---

Return your response as a JSON object with the following structure:
{{
    "answer": an answer from the context.
}}

Always return your response as a JSON object.
"""

class QAFormat_RAG(BaseModel):
    answer: str = Field(default=None, description="Generated answer on question from the context")

def compose_qa(vector_store):
    llm = ChatOpenAI(model='gpt-4o', temperature=0)

    retriever = vector_store.as_retriever(search_kwargs={"k": 10})

    compressor = CohereRerank(model="rerank-english-v3.0")
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=compressor, base_retriever=retriever
    )

    parser = JsonOutputParser(pydantic_object=QAFormat_RAG)

    prompt = PromptTemplate(
        template=rag_prompt,
        input_variables=["context", "text_input", "image_description"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )

    chain = (prompt | llm | parser)

    return chain, compression_retriever
